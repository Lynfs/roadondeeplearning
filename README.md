# My road on deep learning learning(lol)

---

# Basics informations about neural networks

### What's a activation function? 

well, itâ€™s just a thing function that you use to get the output of node. It is also known as Transfer Function.

### Why we use Activation functions with Neural Networks?

It is used to determine the output of neural network like yes or no. It maps the resulting values in between 0 to 1 or -1 to 1 etc. (depending upon the function).

### Sigmoid function

**f(z) = 1/(1+e^(-z))**

### Tanh 

**tanh(t) = ((e^t)-(e^(-t)))/((e^t)+(e^(-t)))**

## What's derivative?

(wikitime): The derivative of a function of a real variable measures the sensitivity to change of the function value (output value) with respect to a change in its argument (input value). Derivatives are a fundamental tool of calculus. For example, the derivative of the position of a moving object with respect to time is the object's velocity: this measures how quickly the position of the object changes when time advances.

The derivative of a function of a single variable at a chosen input value, when it exists, is the slope of the tangent line to the graph of the function at that point. The tangent line is the best linear approximation of the function near that input value. For this reason, the derivative is often described as the "instantaneous rate of change", the ratio of the instantaneous change in the dependent variable to that of the independent variable.

## why do we need to use the derivative?

When updating the curve, to know in which direction and how much to change or update the curve depending upon the slope.That is why we use differentiation in almost every part of Machine Learning and Deep Learning.
